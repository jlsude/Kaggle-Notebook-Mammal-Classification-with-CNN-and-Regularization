{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyNb/sUVqGATNZhaG+WFNbQl"},"accelerator":"TPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":6961629,"sourceType":"datasetVersion","datasetId":3999173}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/cmosbattery/mammal-classification-with-cnn-and-regularization?scriptVersionId=219007577\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Mammal Classification with CNN and Regularization\n\nIn this Notebook, we will develop a Convolutional Neural Network (CNN) model that trains on an image dataset of mammals belonging to 45 classes. The dataset used came from the Mammals Image Classification Dataset (45 Animals). We will also apply model regularization techniques to address overfitting and improve the generalization of the model.","metadata":{"id":"PYlsZ7W-Y4JY"}},{"cell_type":"markdown","source":"## 1. Setup\n\nIn this section, we set up the environment and import the necessary libraries for building the CNN model, as well as for visualizing the data and handling the dataset. We will use TensorFlow for the CNN model and Matplotlib for data visualization.","metadata":{"id":"ebTmGNoWbRlF"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport PIL\nimport os\nimport random\nimport shutil\nimport zipfile\nfrom collections import defaultdict","metadata":{"id":"1dNWLQ8nbQX1","executionInfo":{"status":"ok","timestamp":1736140370660,"user_tz":-480,"elapsed":283,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:05:30.055343Z","iopub.execute_input":"2025-01-08T16:05:30.055725Z","iopub.status.idle":"2025-01-08T16:05:38.100147Z","shell.execute_reply.started":"2025-01-08T16:05:30.055696Z","shell.execute_reply":"2025-01-08T16:05:38.099283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Data Preprocessing\n\nIn this section, we preprocess the dataset to ensure that the images are ready for model training. This includes organizing the data, balancing the number of sample images across all classes, applying necessary transformations such as resizing, and splitting the dataset into training and validation sets for optimal model evaluation.","metadata":{"id":"yOgotlrWccTW"}},{"cell_type":"code","source":"data_directory = Path(\"/kaggle/input/mammals-image-classification-dataset-45-animals/mammals\")\nimage_count = len(list(data_directory.rglob('*.*')))\nprint(f\"The number of images present in the dataset: {image_count}\")","metadata":{"id":"k4KiISxWbjh8","executionInfo":{"status":"ok","timestamp":1736140375050,"user_tz":-480,"elapsed":2522,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"cdf266e8-3a8a-4558-868c-0547c0709958","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:05:38.100973Z","iopub.execute_input":"2025-01-08T16:05:38.101388Z","iopub.status.idle":"2025-01-08T16:06:17.046567Z","shell.execute_reply.started":"2025-01-08T16:05:38.101366Z","shell.execute_reply":"2025-01-08T16:06:17.045733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dictionary to store the count of images per class\nimage_count_per_class = defaultdict(int)\n\n# Iterate through each class directory\nfor class_dir in data_directory.iterdir():\n    if class_dir.is_dir():  # Check if it's a directory\n        class_name = class_dir.name\n        image_count_per_class[class_name] = len(list(class_dir.glob('*.jpg')))\n\n# Prepare data for plotting\nclass_names = list(image_count_per_class.keys())\nimage_counts = list(image_count_per_class.values())\n\nplt.figure(figsize=(9, 6))\nplt.barh(class_names, image_counts)\nplt.title(f\"Image Count per Class ({len(image_count_per_class)} Mammal Classes)\")\nplt.xlabel(\"Number of Images\")\nplt.ylabel(\"Class Names\")\nplt.tight_layout()\nplt.show","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:06:17.047386Z","iopub.execute_input":"2025-01-08T16:06:17.047693Z","iopub.status.idle":"2025-01-08T16:06:17.86404Z","shell.execute_reply.started":"2025-01-08T16:06:17.047669Z","shell.execute_reply":"2025-01-08T16:06:17.863067Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Some of the classes have greater amount of images than others, this creates data imbalance and could potentially cause bias during the training process. This results for them have better representation during the training than those who have few images. With that, we will only limit them to only having 200 images per class.","metadata":{}},{"cell_type":"code","source":"REQ_IMAGE_COUNT = 200\n\n# Create a list to store the filtered images\nfiltered_images = []\n\n# Dictionary to store the new count of images per class after filtering\nfiltered_image_count_per_class = defaultdict(int)\n\n# Iterate through each class directory\nclass_directories = [d for d in data_directory.iterdir() if d.is_dir()]\n\nfor class_dir in class_directories:\n    images = list(class_dir.glob('*.jpg'))\n    \n    # If more than 200 images are present, randomly select 200\n    if len(images) > REQ_IMAGE_COUNT:\n        images = random.sample(images, REQ_IMAGE_COUNT)\n\n    class_name = class_dir.name\n    filtered_image_count_per_class[class_name] = len(images)\n    \n    # Add the selected images to the filtered list\n    filtered_images.extend(images)\n\n# Prepare data for plotting\nclass_names = list(filtered_image_count_per_class.keys())\nimage_counts = list(filtered_image_count_per_class.values())\n\nplt.figure(figsize=(9, 6))\nplt.barh(class_names, image_counts)\nplt.title(f\"Image Count per Class\")\nplt.xlabel(\"Number of Images\")\nplt.ylabel(\"Class Names\")\nplt.tight_layout()\nplt.show\n\n\n# Check the total number of images collected\nprint(f\"Total images collected: {len(filtered_images)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:06:17.86613Z","iopub.execute_input":"2025-01-08T16:06:17.866359Z","iopub.status.idle":"2025-01-08T16:06:18.508006Z","shell.execute_reply.started":"2025-01-08T16:06:17.86634Z","shell.execute_reply":"2025-01-08T16:06:18.507141Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will be storing these filtered classes into a new directory.\n\n> directory: /kaggle/working/filtered_mammals ","metadata":{}},{"cell_type":"code","source":"# Create a new directory to store the filtered dataset\nfiltered_data_directory = Path(\"/kaggle/working/filtered_mammals\")\n\n# Create subdirectories for each class\nfor class_dir in class_directories:\n    class_name = class_dir.name\n    (filtered_data_directory / class_name).mkdir(parents=True, exist_ok=True)\n\n# Copy filtered images to the new directory\nfor image_path in filtered_images:\n    class_name = image_path.parent.name\n    destination = filtered_data_directory / class_name / image_path.name\n    shutil.copy(image_path, destination)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:06:18.509623Z","iopub.execute_input":"2025-01-08T16:06:18.50991Z","iopub.status.idle":"2025-01-08T16:07:18.780285Z","shell.execute_reply.started":"2025-01-08T16:06:18.509887Z","shell.execute_reply":"2025-01-08T16:07:18.779539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We split the dataset for training, which accounts to 80% of the whole dataset, and 20% for validation.","metadata":{}},{"cell_type":"code","source":"IMAGE_BATCH = 32\nIMAGE_SIZE = (150, 150)\nVAL_SPLIT = 0.2\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(\n    filtered_data_directory,\n    validation_split=VAL_SPLIT,\n    subset=\"training\",\n    seed=123,\n    image_size=(IMAGE_SIZE),\n    batch_size=IMAGE_BATCH,\n    label_mode='int'\n)\n\nval_dataset = tf.keras.utils.image_dataset_from_directory(\n    filtered_data_directory,\n    validation_split=VAL_SPLIT,\n    subset=\"validation\",\n    seed=123,\n    image_size=(IMAGE_SIZE),\n    batch_size=IMAGE_BATCH,\n    label_mode='int'\n)","metadata":{"id":"g715yuVubnPr","executionInfo":{"status":"ok","timestamp":1736140386765,"user_tz":-480,"elapsed":5375,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"7a08dd98-b383-43bb-b6f3-12eb294aedf4","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:18.781015Z","iopub.execute_input":"2025-01-08T16:07:18.781218Z","iopub.status.idle":"2025-01-08T16:07:22.031171Z","shell.execute_reply.started":"2025-01-08T16:07:18.7812Z","shell.execute_reply":"2025-01-08T16:07:22.030292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will do a final check on the number of classes present in the training dataset below which is indeed 45 classes.","metadata":{}},{"cell_type":"code","source":"class_names = train_dataset.class_names\nprint('Number of classes:', len(class_names), \"\\n\", class_names)","metadata":{"id":"zeR7_h8vcm4r","executionInfo":{"status":"ok","timestamp":1736140399609,"user_tz":-480,"elapsed":277,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"3b042c3d-b471-4b27-a685-bb8b211d51a2","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:22.032126Z","iopub.execute_input":"2025-01-08T16:07:22.032427Z","iopub.status.idle":"2025-01-08T16:07:22.037478Z","shell.execute_reply.started":"2025-01-08T16:07:22.032398Z","shell.execute_reply":"2025-01-08T16:07:22.036656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will visually check the images contained in the classes of the training dataset.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nfor images, labels in train_dataset.take(1):\n  for i in range(15):\n    ax = plt.subplot(3, 5, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"id":"kZOAo3YEfIpk","executionInfo":{"status":"ok","timestamp":1736140404738,"user_tz":-480,"elapsed":3656,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"99b9653b-91a8-4da9-d20d-7cff9638cf5a","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:22.038246Z","iopub.execute_input":"2025-01-08T16:07:22.038449Z","iopub.status.idle":"2025-01-08T16:07:23.784302Z","shell.execute_reply.started":"2025-01-08T16:07:22.038431Z","shell.execute_reply":"2025-01-08T16:07:23.783106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.cache().shuffle(buffer_size=1000).prefetch(buffer_size=AUTOTUNE)\nval_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"id":"F5zYEYoJfiaD","executionInfo":{"status":"ok","timestamp":1736140411781,"user_tz":-480,"elapsed":263,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:23.785478Z","iopub.execute_input":"2025-01-08T16:07:23.785898Z","iopub.status.idle":"2025-01-08T16:07:23.801333Z","shell.execute_reply.started":"2025-01-08T16:07:23.785857Z","shell.execute_reply":"2025-01-08T16:07:23.800325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Prefetching is done in order to optimize data loading and improve the training time efficiency.","metadata":{}},{"cell_type":"markdown","source":"## 3. Building and Training the Baseline Model\n\nFor the initial baseline model, we will train the CNN with a standard configuration of three convolutional layers. The model will run for 20 epochs to observe how well the baseline performs with simple architecture. The model will be validated on the separate validation subdataset to assess its performance and observe any overfitting. ","metadata":{"id":"rFIk-HQ_tkwB"}},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel = Sequential([\n    layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    layers.Rescaling(1./255),\n\n    # First layer with 16 filters\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    # Second layer with 32 filters\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    # Third layer with 64 filters\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.summary()","metadata":{"id":"XNipsCETsgqy","executionInfo":{"status":"ok","timestamp":1736140440777,"user_tz":-480,"elapsed":1514,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"0b17516b-9481-4793-a5cd-bd618a465849","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:23.80269Z","iopub.execute_input":"2025-01-08T16:07:23.803135Z","iopub.status.idle":"2025-01-08T16:07:23.909228Z","shell.execute_reply.started":"2025-01-08T16:07:23.803087Z","shell.execute_reply":"2025-01-08T16:07:23.908568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Before training the model, we compile it with the Adam optimizer, which adapts the learning rate for efficient training. The Sparse Categorical Crossentropy loss function is used since the task is a multi-class classification problem with integer labels. The model will also track accuracy as a performance metric during training","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)","metadata":{"id":"gWwq0f3kt6Ia","executionInfo":{"status":"ok","timestamp":1736140445995,"user_tz":-480,"elapsed":244,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:23.910065Z","iopub.execute_input":"2025-01-08T16:07:23.910385Z","iopub.status.idle":"2025-01-08T16:07:23.923295Z","shell.execute_reply.started":"2025-01-08T16:07:23.910355Z","shell.execute_reply":"2025-01-08T16:07:23.922409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=20\n)","metadata":{"id":"nDV1n1hctyBD","executionInfo":{"status":"ok","timestamp":1736140553703,"user_tz":-480,"elapsed":102904,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"045688dd-4e6a-4322-e680-69b4a254111c","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:07:23.924059Z","iopub.execute_input":"2025-01-08T16:07:23.924358Z","iopub.status.idle":"2025-01-08T16:08:13.133395Z","shell.execute_reply.started":"2025-01-08T16:07:23.924325Z","shell.execute_reply":"2025-01-08T16:08:13.132701Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to visualize the training and validation logs from model's history\ndef vis_logs(model):\n    acc = model.history['accuracy']\n    val_acc = model.history['val_accuracy']\n    \n    loss = model.history['loss']\n    val_loss = model.history['val_loss']\n    \n    epochs_range = range(len(acc))\n    \n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel(\"Completed Epochs\")\n    plt.ylabel(\"Accuracy\")\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel(\"Completed Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.show()\n\nvis_logs(history)","metadata":{"id":"_RvwUipzt4Kb","executionInfo":{"status":"ok","timestamp":1736140556735,"user_tz":-480,"elapsed":876,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"f8a960b2-f989-440f-a0dc-72fe499ded9a","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:13.135833Z","iopub.execute_input":"2025-01-08T16:08:13.136055Z","iopub.status.idle":"2025-01-08T16:08:13.527761Z","shell.execute_reply.started":"2025-01-08T16:08:13.136036Z","shell.execute_reply":"2025-01-08T16:08:13.526668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After training for 20 epochs, we observe significant gaps between the accuracy and loss in both plots. This is a clear indication of **overfitting** wherein the model performs too well in the training data, however in the validation, it is not performing well on the unforseen data. \n\nTo address this issue of overfitting of our baseline model, we plan to implement the following techniques:\n\n- **Data Augmentation**: Use data augmentation to artificially increase the size of the training set, providing the model with more varied examples to learn from.\n- **Dropout**: Introduce dropout layers to randomly deactivate neurons during training, forcing the model to learn more robust features.\n- **L2 Regularization**: Apply L2 regularization to penalize large weights and encourage the model to generalize better.\n\nAdditionally, we will implement the early stopping mechanism to halt training when the validation loss stops improving and adjust the learning rate if the validation performance plateaus during training.","metadata":{}},{"cell_type":"markdown","source":"## 4. Data Augmentation\n\nThe training images will be randomly augmented both horizontally and vertically with random rotation and zooming. This allows the model in trainig session to learn all the possible features even if the images are rotated or zoomed. This augmentation approach will be configured as a layer to the model.","metadata":{"id":"8Kvo3PPTwc8A"}},{"cell_type":"code","source":"data_augmentation = keras.Sequential([\n    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)","metadata":{"id":"ceeAsWp3w3lp","executionInfo":{"status":"ok","timestamp":1736140566772,"user_tz":-480,"elapsed":269,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:13.529412Z","iopub.execute_input":"2025-01-08T16:08:13.529747Z","iopub.status.idle":"2025-01-08T16:08:13.544831Z","shell.execute_reply.started":"2025-01-08T16:08:13.529715Z","shell.execute_reply":"2025-01-08T16:08:13.54375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_dataset.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"id":"iJp5g3S1w37h","executionInfo":{"status":"ok","timestamp":1736140573331,"user_tz":-480,"elapsed":4435,"user":{"displayName":"John Louie","userId":"15732993297676519558"}},"outputId":"b9c516d1-a01f-4a79-8cd0-3cebd80d0f21","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:13.545758Z","iopub.execute_input":"2025-01-08T16:08:13.546073Z","iopub.status.idle":"2025-01-08T16:08:15.367967Z","shell.execute_reply.started":"2025-01-08T16:08:13.546043Z","shell.execute_reply":"2025-01-08T16:08:15.366826Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After we define the data augmentation layer, we will insert it in between the input (layers.Input) layer and the normalization (layers.Rescaling) layer.","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel_2 = Sequential([\n    layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    data_augmentation, \n    layers.Rescaling(1./255),\n\n    # First layer with 16 filters\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    # Second layer with 32 filters\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    # Third layer with 64 filters\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel_2.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:15.368935Z","iopub.execute_input":"2025-01-08T16:08:15.369259Z","iopub.status.idle":"2025-01-08T16:08:15.450258Z","shell.execute_reply.started":"2025-01-08T16:08:15.369229Z","shell.execute_reply":"2025-01-08T16:08:15.449353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\nFor this training, we will train the model for 20 epochs and set the early stopping mechanism with a patience of **5 epochs**, which will stop training if the validation loss does not improve for **5 consecutive epochs**. Additionally, we will adjust the learning rate by reducing it by **50%** if the validation loss plateaus, with a patience of **3 epochs** and a minimum learning rate of **1e-6**.","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n\nmodel_2.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=5\n)\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.5, \n    patience=3, \n    min_lr=1e-6\n)\n\nhistory_2 = model_2.fit(\n  train_dataset,\n  validation_data=val_dataset,\n  epochs=20,\n  callbacks=[early_stopping, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:08:15.451246Z","iopub.execute_input":"2025-01-08T16:08:15.45159Z","iopub.status.idle":"2025-01-08T16:09:20.506757Z","shell.execute_reply.started":"2025-01-08T16:08:15.451557Z","shell.execute_reply":"2025-01-08T16:09:20.505871Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis_logs(history_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:09:20.507559Z","iopub.execute_input":"2025-01-08T16:09:20.507814Z","iopub.status.idle":"2025-01-08T16:09:20.844355Z","shell.execute_reply.started":"2025-01-08T16:09:20.507793Z","shell.execute_reply":"2025-01-08T16:09:20.843481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After training the model with data augmentation for **20 epochs**, we observe that both the training and validation accuracy and loss improved over time, showing some reduction in overfitting. As the training process reached the end of the epoch, the learning rate further decreased to **5x10^-5**, indicating that at the later stages of the training a degradation in validation performance is being observed.\n\nMoving forward, to further address the overfitting issue, we will apply regularization techniques, such as dropout, with the goal of enhancing the model's performance on the validation data. We will also increasing the minimum number of filters to **32** from the initial value of **16**.","metadata":{}},{"cell_type":"markdown","source":"## 5. Model Regularization: Dropout\n\nWe will add a **Dropout layer** with a rate of **10%** after the **Dense layer** to help model reduce the overfitting by randomly deactivating the neurons during the training process.","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel_3 = Sequential([\n    layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    data_augmentation, \n    layers.Rescaling(1./255),\n\n    # First layer with 32 filters\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    # Second layer with 64 filters\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    # Third layer with 128 filters\n    layers.Conv2D(128, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel_3.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:09:20.845344Z","iopub.execute_input":"2025-01-08T16:09:20.845708Z","iopub.status.idle":"2025-01-08T16:09:20.913334Z","shell.execute_reply.started":"2025-01-08T16:09:20.845675Z","shell.execute_reply":"2025-01-08T16:09:20.912688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For this training, we compile the model with the newly added Dropout layer and an updated learning rate of 1x10^-5. The model will be trained for the same number of epochs as the previous training.","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n\nmodel_3.compile(optimizer=optimizer,\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                metrics=['accuracy'])\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=5\n)\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.5, \n    patience=3, \n    min_lr=1e-8\n)\n\nhistory_3 = model_3.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=20,\n    callbacks=[early_stopping, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:09:20.91412Z","iopub.execute_input":"2025-01-08T16:09:20.914412Z","iopub.status.idle":"2025-01-08T16:10:58.603374Z","shell.execute_reply.started":"2025-01-08T16:09:20.914381Z","shell.execute_reply":"2025-01-08T16:10:58.602681Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis_logs(history_3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:10:58.60426Z","iopub.execute_input":"2025-01-08T16:10:58.604488Z","iopub.status.idle":"2025-01-08T16:10:59.183737Z","shell.execute_reply.started":"2025-01-08T16:10:58.604467Z","shell.execute_reply":"2025-01-08T16:10:59.182882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After training, we observe a gradual reduction in both training and validation loss. Additionally, the validation accuracy shows an upward trend, getting closer to the training accuracy, indicating that the model is learning the patterns in the data while managing to reduce overfitting. The addition of **Dropout rate** of **10%** is helping in improving generalization of the model during the validation process.","metadata":{}},{"cell_type":"markdown","source":"## 5. Model Regularization: L2 Regularization\n\nTo further improve the generalization of the model and reduce the risk of overfitting, we will be implementing **L2 regularization** across all convolutional layers. We apply an **L2 penalty** of **0.01** to each convolutional layer using the **kernel_regularizer** parameter. This adjustment aims to strike a balance between model flexibility and stability during training.","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)\nl2 = 0.01\n\nmodel_4 = Sequential([\n    layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    data_augmentation, \n    layers.Rescaling(1./255),\n\n    # First layer with 32 filters\n    layers.Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2)),\n    layers.MaxPooling2D(),\n    \n    # Second layer with 64 filters\n    layers.Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2)),\n    layers.MaxPooling2D(),\n\n    # Third layer with 128 filters\n    layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(l2)),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel_4.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:10:59.184714Z","iopub.execute_input":"2025-01-08T16:10:59.18501Z","iopub.status.idle":"2025-01-08T16:10:59.252082Z","shell.execute_reply.started":"2025-01-08T16:10:59.184978Z","shell.execute_reply":"2025-01-08T16:10:59.251413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n\nmodel_4.compile(optimizer=optimizer,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n    )\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.5, \n    patience=3, \n    min_lr=1e-6\n)\n\n\nhistory_4 = model_4.fit(\n  train_dataset,\n  validation_data=val_dataset,\n  epochs=20,\n  callbacks=[early_stopping, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:10:59.252781Z","iopub.execute_input":"2025-01-08T16:10:59.253041Z","iopub.status.idle":"2025-01-08T16:12:23.65935Z","shell.execute_reply.started":"2025-01-08T16:10:59.253019Z","shell.execute_reply":"2025-01-08T16:12:23.658598Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis_logs(history_4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:12:23.660291Z","iopub.execute_input":"2025-01-08T16:12:23.660578Z","iopub.status.idle":"2025-01-08T16:12:24.012089Z","shell.execute_reply.started":"2025-01-08T16:12:23.660554Z","shell.execute_reply":"2025-01-08T16:12:24.011168Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After training, both validation accuracy and loss showed consistent improvement, with the model achieving a final validation accuracy of **16.06%** and validation loss of **3.3828**. L2 regularization effectively addressed overfitting by penalizing large weight values, leading to a more generalized model. The steady decline in validation loss indicates that the model continues to learn meaningful features without overfitting.","metadata":{}},{"cell_type":"markdown","source":"## 6. Conclusion\n\nWe are able to develop a Convolutional Neural Network model that is trained on the [Mammals Image Classification Dataset (45 Animals)](https://www.kaggle.com/datasets/asaniczka/mammals-image-classification-dataset-45-animals) with **45 classes**. As we build the baseline model with standard configuration of three convolutional layers, we have observed an overfitting issue, with the training accuracy reaching as high as **98%** while validation accuracy remained around **~20%**. To address the issue and improve the performance, we implemented **data augmentation**, **dropout**, and **L2 regularization** which helped improve generalization and stabilize the model's performance. \n\nGiven the dataset size of only **200 images per class**, further increasing the number of epochs did not yield significant improvements in performance. The model achieved stability, indicating that the current dataset size might limit further accuracy gains.","metadata":{}}]}